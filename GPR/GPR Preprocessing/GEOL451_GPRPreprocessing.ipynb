{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNFhptDY4t1k"
   },
   "source": [
    "# GPR Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJBKGbt85TXL"
   },
   "source": [
    "Before we begin working on the GPR data itself, we would like to investigate the metadata and other associated data (i.e., GPS data) to make sure the data we collected is of high quality and that there are no surprises in our dataset (for example, the GPS system was not functioning properly, or the lengths of the profiles are different than what we expected, etc.).\n",
    "\n",
    "These scripts are specific to data collected by the Sensors and Software Noggin250+ GPR instrument, which is the data we will use in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the first line of code in the next cell if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib #To read and manipulate filepaths\n",
    "import csv #to read files\n",
    "import datetime #For manipulating dates and times\n",
    "\n",
    "import pandas as pd #to organize data. This is not included in the python standard libary and will need to be installed\n",
    "import numpy as np #for numerical manipulation. This is not included in the python standard library and will need to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEk8O53xFjCy"
   },
   "source": [
    "## Read, Convert, and Export GPS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTXExmwWYfAE"
   },
   "source": [
    "Now, we will convert our GPS data to a .csv file that can be manipulated and read in by various programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the raw GPGGA sentences first (you can also just open the .gps file). \n",
    "\n",
    "We'll print up the first 10 lines of the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace #1 at position 0.000000\n",
      "\n",
      "$GPVTG,118.3,T,,,000.02,N,000.04,K,A*4D\n",
      "\n",
      "$GPGGA,164010.60,4018.7801826,N,08819.6413086,W,1,10,0.9,217.53,M,-33.93,M,,*5E\n",
      "\n",
      "Trace #11 at position 0.250000\n",
      "\n",
      "$GPVTG,84.7,T,,,000.46,N,000.86,K,A*77\n",
      "\n",
      "$GPGGA,164013.60,4018.7801853,N,08819.6412256,W,1,10,0.9,217.54,M,-33.93,M,,*56\n",
      "\n",
      "Trace #21 at position 0.500000\n",
      "\n",
      "$GPVTG,96.3,T,,,000.85,N,001.58,K,A*7D\n",
      "\n",
      "$GPGGA,164014.40,4018.7801693,N,08819.6409945,W,1,10,0.9,217.54,M,-33.93,M,,*52\n",
      "\n",
      "Trace #31 at position 0.750000\n",
      "\n",
      "$GPVTG,85.3,T,,,000.82,N,001.51,K,A*71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDirectory = \"../GPRSampleData/\"\n",
    "#Read in .gps files only, with relevant information only\n",
    "GPSFiles = pathlib.Path(dataDirectory).glob('*.GPS')\n",
    "for f in GPSFiles:\n",
    "    lines = [] #Create an empty, resuable list for each line\n",
    "\n",
    "    with open(str(f)) as cf:\n",
    "        for row_number, row in enumerate(cf):\n",
    "            if row_number < 11:\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the $GPGGA data (which shows the GPS location), not the #GPVTG (which shows the direction of travel)\n",
    "\n",
    "Find more information about these \"sentence\" formats [here](https://www.rfwireless-world.com/Terminology/GPS-sentences-or-NMEA-sentences.html)\n",
    "\n",
    "The following cell will read that data, format it into a table (or dataframe), then export that table to a .csv file.\n",
    "\n",
    "That .csv file will export to the same directory that the .gps file is in. You can find it there for the next steps of your preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1660578862718,
     "user": {
      "displayName": "Riley Balikian",
      "userId": "00634850266583991390"
     },
     "user_tz": 300
    },
    "id": "WGI0g8m8QFoW",
    "outputId": "7520507a-ccf7-48c1-b58b-92065cd89043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ScanNo                Time   File   Latitude  Longitude  Elev_m  Quality  \\\n",
      "ID                                                                              \n",
      "0         1 2022-07-21 16:40:10  LINE0  40.313003 -88.327355  217.53        1   \n",
      "1        11 2022-07-21 16:40:13  LINE0  40.313003 -88.327354  217.54        1   \n",
      "2        21 2022-07-21 16:40:14  LINE0  40.313003 -88.327350  217.54        1   \n",
      "3        31 2022-07-21 16:40:15  LINE0  40.313003 -88.327347  217.55        1   \n",
      "4        41 2022-07-21 16:40:15  LINE0  40.313003 -88.327345  217.55        1   \n",
      "..      ...                 ...    ...        ...        ...     ...      ...   \n",
      "464    4641 2022-07-21 16:43:12  LINE0  40.313026 -88.325976  215.38        1   \n",
      "465    4651 2022-07-21 16:43:12  LINE0  40.313027 -88.325971  215.40        1   \n",
      "466    4661 2022-07-21 16:43:13  LINE0  40.313027 -88.325968  215.38        1   \n",
      "467    4671 2022-07-21 16:43:13  LINE0  40.313027 -88.325965  215.35        1   \n",
      "468    4681 2022-07-21 16:43:14  LINE0  40.313028 -88.325962  215.37        1   \n",
      "\n",
      "     Satellites  HDOP  GeoidSep  \n",
      "ID                               \n",
      "0            10   0.9    -33.93  \n",
      "1            10   0.9    -33.93  \n",
      "2            10   0.9    -33.93  \n",
      "3            10   0.9    -33.93  \n",
      "4            10   0.9    -33.93  \n",
      "..          ...   ...       ...  \n",
      "464           7   2.5    -33.93  \n",
      "465           7   2.5    -33.93  \n",
      "466           7   2.5    -33.93  \n",
      "467           8   1.3    -33.93  \n",
      "468           8   1.3    -33.93  \n",
      "\n",
      "[469 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#This script reads in the .gps files collected with the Sensors and Software Noggin+ 250\n",
    "#  These gps files contain GPGGA sentences. This file converts those into a .csv file with lat/lon that can be read more easily by other software, including GIS and python\n",
    "dataDirectory = \"../GPRSampleData/\"\n",
    "#Read in .gps files only, with relevant information only\n",
    "GPSFiles = pathlib.Path(dataDirectory).glob('*.GPS')\n",
    "\n",
    "allLines=[] #Create an empty list for appending information from each GPGGA line in the .gps file. Will be converted to dataframe\n",
    "\n",
    "#Go through each .gps file and convert GPGGA data into a dataframe\n",
    "for f in GPSFiles:\n",
    "    lines = [] #Create an empty, resuable list for each line\n",
    "\n",
    "    with open(str(f)) as cf:\n",
    "        inData = csv.reader(cf, delimiter=',') #Open file and read it into inData\n",
    "        for row in inData: #Go through each row at a time\n",
    "            if row[0] == '$GPGGA': #For the rows that contain the GPGGA sentence (i.e., the GPS data)...\n",
    "                mdfTime = f.stat().st_mtime #Get time of file creation from file metadata itself\n",
    "                mdfTime = datetime.datetime.fromtimestamp(mdfTime) #Convert that information and add it as a column\n",
    "                row.append(f.stem) #Add the line name.filename to our list\n",
    "                row.append(mdfTime) #Add the file creation time to our list\n",
    "                lines[-1] = lines[-1] + row #Cleanup\n",
    "            elif '#' in row[0]:\n",
    "                #If it is not line with a GPGGA sentence, it might be a line containing information about the trace the GPS point is assocaited with\n",
    "                currRow = row[0]\n",
    "                startInd = int(currRow.find('#'))+1\n",
    "                newStr = currRow[startInd:]\n",
    "                endInd = int(newStr.find(' '))\n",
    "                traceNo = int(newStr[:endInd])\n",
    "                lines.append([traceNo]) #Add that trace information to our list\n",
    "            else:\n",
    "                pass #Do not collect information from the other lines\n",
    "    for l in lines:\n",
    "        allLines.append(l) #Add each GPS point as a separate \"row\" in the allLines list\n",
    "\n",
    "inDF = pd.DataFrame(allLines) #Convert allLines list to dataframe\n",
    "\n",
    "#Create new dataframe for data manipulation, and formatting\n",
    "df = inDF.copy() #So we can preserve the original data as we manipulate it\n",
    "df.dropna(axis=0, inplace=True, how='any') #Drop any GPS data (or errant row) that does not contain all relevant information\n",
    "cols = [\"Trace\",\"StrType\", \"Time\", \"Lat_Unformat\", \"LatDir\", \"Lon_Unformat\", \"LonDir\", \"Quality\", \"Satellites\", \"HDOP\", \"Elev_m\", \"ElevUnit\", \"GeoidOffset\", \"GeoidOffsetUnit\", \"Col\", \"STID\", \"Filename\",\"FileCreateTime\"]\n",
    "df.columns = cols #Assign column labels\n",
    "floatCols = [\"Lat_Unformat\", \"Lon_Unformat\",\"Quality\",\"Satellites\",\"HDOP\",\"Elev_m\",\"GeoidOffset\"] #Note columns to be converted to float for easier manipulation later\n",
    "\n",
    "for c in floatCols:#conver some of the data (read in as strings) to numeric/float datatype\n",
    "    df[c] = pd.to_numeric(df[c],errors='coerce')#.astype(float,errors='ignore') #last part not needed in current iteration\n",
    "\n",
    "df.dropna(axis=0, inplace=True, how='any',)#Again, drop any errant columns\n",
    "df.reset_index(drop=True, inplace=True) #Reset the index with our new data\n",
    "\n",
    "#Add new columns for time\n",
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"],format=\"%H%M%S.%f\")\n",
    "df[\"year\"] = df[\"FileCreateTime\"].dt.year\n",
    "df[\"month\"] = df[\"FileCreateTime\"].dt.month\n",
    "df[\"day\"] = df[\"FileCreateTime\"].dt.day\n",
    "df[\"hour\"] = df[\"Time\"].dt.hour\n",
    "df[\"minute\"] = df[\"Time\"].dt.minute\n",
    "df[\"second\"] = df[\"Time\"].dt.second\n",
    "\n",
    "df[\"CollectTime\"] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "#Reformat GGA sentence coordinates to decimal degree\n",
    "df[\"LatDeg\"] = (df[\"Lat_Unformat\"]/100).astype(float)\n",
    "df[\"LatDeg\"] = np.floor(df[\"LatDeg\"])\n",
    "df[\"LonDeg\"] = (df[\"Lon_Unformat\"]/100).astype(float)\n",
    "df[\"LonDeg\"] = np.floor(df[\"LonDeg\"])\n",
    "\n",
    "df[\"LatMin\"] = df[\"Lat_Unformat\"].astype(str)\n",
    "df[\"LatMin\"] = df.LatMin.str.extract('(?<=^..)(.*)') #This uses a \"regular expression\" to find the right substring to extract\n",
    "df[\"LonMin\"] = df[\"Lon_Unformat\"].astype(str)\n",
    "df[\"LonMin\"] = (df.LonMin.str.extract('(?<=^..)(.*)')) #This uses a \"regular expression\" to find the right substring to extract\n",
    "\n",
    "df[\"LatMinDec\"] = pd.to_numeric(df[\"LatMin\"])/60\n",
    "df[\"LonMinDec\"] = pd.to_numeric(df[\"LonMin\"])/60\n",
    "\n",
    "df[\"Latitude\"] = df[\"LatDeg\"]+df[\"LatMinDec\"]\n",
    "df[\"Longitude\"] = df[\"LonDeg\"]+df[\"LonMinDec\"]\n",
    "\n",
    "for d in enumerate(df[\"LatDir\"]):\n",
    "    if d[1] == 'S':\n",
    "        df.loc[d[0],\"Latitude\"] = df.loc[d[0],\"Latitude\"] *-1\n",
    "\n",
    "for d in enumerate(df[\"LonDir\"]):\n",
    "    if d[1] == 'W':\n",
    "        df.loc[d[0],\"Longitude\"] = df.loc[d[0],\"Longitude\"] *-1\n",
    "\n",
    "#Create dataframe for output, with just the most important columns\n",
    "outDF = pd.DataFrame()\n",
    "\n",
    "outDF.index.name=\"ID\"\n",
    "outDF[\"ScanNo\"] = df['Trace']\n",
    "outDF[\"Time\"] = df[\"CollectTime\"]\n",
    "outDF[\"File\"] = df[\"Filename\"]\n",
    "outDF[\"Latitude\"] = df[\"Latitude\"]\n",
    "outDF[\"Longitude\"] = df[\"Longitude\"]\n",
    "outDF[\"Elev_m\"] = df[\"Elev_m\"]\n",
    "outDF[\"Quality\"] = df[\"Quality\"]\n",
    "outDF[\"Satellites\"] = df[\"Satellites\"]\n",
    "outDF[\"HDOP\"] = df[\"HDOP\"]\n",
    "outDF[\"GeoidSep\"] = df[\"GeoidOffset\"]\n",
    "\n",
    "#Preview, Export\n",
    "print(outDF)\n",
    "outGPSFilePath = pathlib.Path(dataDirectory).joinpath('AllGPSPts_GPR_GEOL451Data.csv')\n",
    "outDF.to_csv(outGPSFilePath)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnCq7OCkPVMP9pYZMf6QrG",
   "collapsed_sections": [],
   "name": "GEOL451_Exercise4Bonus_a_GPRPreprocessing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
